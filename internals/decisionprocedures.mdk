# Decision Procedures


We will apply the following taxonomy when discussing the theory solvers.
It extends the reduction approach to decision procedures [@KapurZarbaReduction]
as explained in the context of Z3 in [@MouraB09].


* Base theories - other theory solvers build on top of base theories
  * The base theories in z3 are Boolean theories, the theory of uninterpreted functions and the theory of arithmetic.
* Reducible theories 
  * Theories that can be solved by reducing directly into base theories.
  * Instances: Arrays, IEEE floating points, algebraic datatypes, recursive functions.
* Hybrid theories 
  * Theories that combine non-disjoint signatures from different theories.
  * Instances: Sequences, Model-based quantifier instantiation.
* External theories 
  * Theories that may be developed externally by propagating consequences and identifying conflicts.
  * Instance: an external propagator plugin.


~ Figure { #fig-z3core; caption: "Architecture of Z3's SMT Core solver." }
~~ Snippet

\begin{picture}(270,210)(0,-10)

\multiput(75,40)(0,77){3}{\oval(20,20)[tr]}
\multiput(75,0)(0,77){3}{\oval(20,20)[br]}
\multiput(10,40)(0,77){3}{\oval(20,20)[tl]}
\multiput(0,0)(0,77){3}{\line(0,1){40}}
\multiput(85,0)(0,77){3}{\line(0,1){40}}
\multiput(10,50)(0,77){3}{\line(1,0){65}}
\multiput(10,-10)(0,77){3}{\line(1,0){65}}
\multiput(10,0)(0,77){3}{\oval(20,20)[bl]}

\put(16,155){\shortstack{E-matching\\ based \\ Quantifier\\ Instantiation}}
\put(16, 92){\shortstack{EUF + SAT}}
\put(16,0){\shortstack{Model\\ based \\ Quantifier\\ Instantiation}}

\put(267,195){\oval(20,20)[tr]}
\put(267,0){\oval(20,20)[br]}
\put(149,195){\oval(20,20)[tl]}
\put(149,0){\oval(20,20)[bl]}
\put(149,-10){\line(1,0){120}}
\put(149,205){\line(1,0){120}}
\put(139,0){\line(0,1){195}}
\put(277,0){\line(0,1){195}}


\multiput(255,20)(0,37){5}{\oval(20,20)[tr]}
\multiput(255,10)(0,37){5}{\oval(20,20)[br]}
\multiput(165,10)(0,37){5}{\oval(20,20)[bl]}
\multiput(165,20)(0,37){5}{\oval(20,20)[tl]}
\multiput(155,10)(0,37){5}{\line(0,1){10}}
\multiput(265,10)(0,37){5}{\line(0,1){10}}
\multiput(165,30)(0,37){5}{\line(1,0){90}}
\multiput(165,0)(0,37){5}{\line(1,0){90}}
\put(170,12){Strings/Sequences}
\put(185,50){Datatypes}
\put(185,86){Bit-vectors}
\put(195,122){Arrays}
\put(185,158){Arithmetic}
\put(190,190){Theories}

\put(42,50){\vector(0,1){17}}
\put(42,67){\vector(0,-1){17}}
\put(42,127){\vector(0,1){17}}
\put(42,144){\vector(0,-1){17}}

\put(85,95){\vector(1,0){54}}
\put(139,95){\vector(-1,0){54}}

\end{picture}
~~
~



## Base Theories

### Boolean Theories
Bit-vectors are in the current solver treated as tuples of Boolean variables and all bit-vector
operations are translated to Boolean SAT. The approach is called bit-blasting.
Only mild equational reasoning is performed over bit-vectors.
The benefits of the CDCL SAT engine have been mostly enjoyed for applications in symbolic execution 
of 32-bit arithmetic instructions. Bit-blasting has its limitations: applications that use quantifiers
and applications around smart contracts that use 256 bits per word are stressing this approach. A
revised bit-vector solver that integrates algebraic reasoning and lazy bit-blasting is therefore currently
being developed.

Cardinality and Pseudo-Boolean inequalities can also be translated into CNF clauses. It is often an advantage
when there are very few variables in the summations, but the overhead of translation can quickly become
impractical. Z3 therefore contains dedicated solvers for cardinality and Pseudo-Boolean constraints.

~ Framed
Examples of cardinality, Bit-vectors
~


### Equality and Uninterpreted Functions

This theory captures a shared property of all theory: that equality is a congruence relation. 
The theory is described many places, including in [@BjornerMNW18].


Let us use a simple example to illustrate the scope and main functionality of congruence closure
based decision procedures for equality. We are given two equalities and one disequality

~ Math
  a \simeq f(f(a)), a \simeq f(f(f(a))), a \not\simeq f(a)
~

Their conjunction is unsatisfiable. Unsatisfiability is established by combining union-find [@UnionFind] data-structures
to maintain equivalence classes and a data-structure of E-graphs to enforce congruences.
In a first step the terms are represented by unique nodes in a DAG structure for every sub-term. We represent the DAG
structure as a sequence of definitions. Then equalities and disequalities are between nodes in DAG.

~ MathPre
  n_1 \equiv f(a), n_2 \equiv f(n_1), n_3 \equiv f(n_2) \\
  a \simeq n_2, a \simeq n_3, a \not\simeq n_1
~

Process equality atoms using union-find. It establishes the equivalence classes

~ Math
 \{  a, n_2, n_3 \}, \{ n_1 \}
~

Then congruence closure triggers whenever there are two nodes, $n_1, n_2$ from different equivalence classes,
labeled by the same function $f$, with equal children. In our case $a, n_2$ belong to the same equivalence class
so the nodes $n_1, n_3$ are merged.

~ Math
\{  a, n_2, n_3, n_1 \}
~

When the children of the equality term $a \simeq n_1$ are merged into the same equivalence class, the
term $a \simeq n_1$ is set to true. This contradicts that $a \simeq n_1$ is already set to false.


#### E-Node

~ Framed
TODO add citations to main sources: DST, NO (Oliveras), Simplify Report
~

The E-Node data-structure is used to implement congruence closure efficiently. The main fields of an E-Node are

~ MathPre
    n : & \langle & f: & Func  & \mbox{function symbol}
        &      & ts: & N^* & \mbox{arguments}
        &      & find: & N \times N \times \Nat & \mbox{link to representative, sibling and class size}
        &      & P:    & N^*   & \mbox{list of parents}            
        &      & cg:   & N    & \mbox{congruence representative}
        &      & j:    & null | Just \times N & \mbox{pointer to justification and node}
        & \rangle
~

When a term $f(ts)$ occurs in a formula used by the solver it is compiled into an E-node $n$.
The E-node $n$ is initialized to

~ Math
 n \leftarrow \langle f = f, ts = ts, \find = (n,n,1), P = null, cg = n, j = null \rangle.
~

The field $\find$ is used to implement union-find. The _root_ of a node is found by
looking up the representative until it is the same node.
Thus, let $(n_1, n_2, sz) = \find(n)$. Then $\rootNode(n) = n$ if $n_1 = n$, otherwise
$\rootNode(n) = \rootNode(n_1)$. We extend $\rootNode$ to apply to a list of nodes by mapping it on each node in the list.
Z3 does not perform path compaction, instead it eagerly updates
the representative of all siblings when nodes are merged. In other words, if roots $n_1, n_2$ are merged
and $n_2$ is made the root, then all siblings $n_s$ of $n_1$ are updated such that $n_s := n_2$.
The second field $n_2$ is the sibling
of $n$ in the same equivalence class. The set of siblings forms a singly linked cyclic list.
The size field $sz$ is the size of the equivalence class. 


Besides the E-nodes the solver maintains a hash-table, we call _etable_, that
is used to find the congruence root of a function application. It maps a
function symbol $f$ and list of arguments to $f$ that are represented by
root E-nodes into a congruence closure root. For the congruence closure
root $n$ it maintains the invariant $n.cg = \mathit{etable}(n.f, \rootNode(n.ts))$.


#### Merge

The main functionality of congruence closure is to ensure that all equivalene classes that follow
from equalities are inferred. It exposes the main function merge($n_1, n_2, j$) to
establish that two nodes $n_1, n_2$ are equal under justification $j$. We describe justifications later
in more detail. The main steps of _merge_ are outlined below.


|:~~~~~~~~~~~~~|:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|
| Roots        | $r_1 \leftarrow \rootNode(n_1), r_2 \leftarrow \rootNode(n_2)$                            |
|              | assume $r_1 \neq r_2$                                                                     |
|              | assume $r_1.sz \leq r_2.sz$                                                               |
| Erase        | __for each__ $p \in r_1.P$ __where__ $p.cg = p$:                                          |
|              | \ \ \ \ erase $\mathit{etable}[p.f, p.ts]$                                                       |
| Update Root  | $r_1.\find \leftarrow r_2$                                                                |
| Justify      | justify($r_1, r_2, j$)                                                                    |
| Insert       | __for each__ $p \in r_1.P$:                                                               |
|              | \ \ __if__ $\mathit{etable}[p.f,p.ts] = null$ __then__                                     |
|              | \ \ \ \ \ $\mathit{etable}[p.f,p.ts] \leftarrow p$                                        |
|              | \ \ $p.cg \leftarrow$ _etable_$[p.f, p.ts]$                                                |
|              | \ \ __if__ $p.cg = p$ __then__                                                            |
|              | \ \ \ \ append $p$ to $r_2.P$                                                             |
|              | \ \ __else__                                                                              |
|              | \ \ \ \ add $\langle p.cg, p, cc\rangle$ to _tomerge_                                     |

* __Roots__: congruence closure always merges current roots of equivalence classes. If the roots are equal, there is nothing to merge.
We assume that $r_2$ is chosen as root. The main mechanism for ensuring congruence closure has sub-quadratic running time
is obtained by applying Hopcroft's method of merging the _lesser_ half. Z3 makes an exception to this rule if $r_1$ is labeled by a term
that qualifies as a _value_. To quickly identify if a congruence class contains a value, such as $1, 2, cons(3, nil)$, it sets the root
of a class to be the node representing the value. 

* __Erase__: Entries of the _etable_ that are stale are removed. An entry is stale if it points to the old root as congruence closure representative.

* __Update Root__: The root is updated along with size of equivalence classes and links into the cyclic list of siblings.

* __Justify__: The _justification_ for a merged equality is updated. We describe this functionality later.

* __Insert__: Finally, the _etable_ is updated by updating the $cg$ field of parents from $r_1$. It maintains a list _tomerge_ of new nodes that are discovered congruent. An outer loop invokes _merge_ on the list of new nodes until it is empty.




#### Unmerge

All operations on the E-Graph can be inverted. For this purpose, every merge is recorded in an _undo trail_.
Other operations that update nodes are recorded in the same trail. For example when $p$ is appended to $r_2.P$
the insertion into the cyclic list of parents is recorded so that it can be reverted. To reverting a merge
requires updating the _etable_ and is sensitive to whether a node was a congruence root:

unmerge($r_1, r_2$):

```
Erase:        for each p in r2.P added from r1.P:
                 erase p from table 
Unjustify:    ....
Revert root:  r1.find := r1
Insert:       for each p in r1.P:
                 insert p if n was cc root before merge

condition for being cc root before merge:
  p.cg == p or !congruent(p, p.cg)

congruent(p,q) := roots of p.ts = roots of q.ts
```

#### Justifications 

A justification is a reason for merging two nodes.
There are two possible reasons for merging nodes:

1. A literal $\ell: s \simeq t$ is asserted. The justification is the literal $\ell$.
2. Nodes are merged due to congruence closure.

~ MathPre
   Just ::= \ell: s \simeq t | cc: f(ts) \simeq f(ts')
~

__NB__: $cc: f(ts) \simeq f(ts')$ is justified _recursively_ by justifying $ts \simeq ts'$.


__Invariant:__ Every non-root node points to a linked list of justifications leading to the root

__NB__ The linked list does not follow direction of union-find.

~ MathPre
    r_1 \leftarrow \rootNode(n_1)
    r_2 \leftarrow \rootNode(n_2)
    r_1.\find \leftarrow r_2
    old justification: n_1 \stackrel{j_1}{\rightarrow} n^1_1 \stackrel{j_2}{\rightarrow} n^2_1 \cdots \stackrel{j_m}{\rightarrow} r_1
    new justification: n_1 \stackrel{j_1}{\leftarrow} n^1_1 \stackrel{j_2}{\leftarrow} n^2_1 \cdots \stackrel{j_m}{\leftarrow} r_1
    add justification: n_1 \stackrel{j}{\rightarrow} n_2
~


![justificationunionfind]
[justificationunionfind]: images/justifiedunionfind.jpg "justificationunionfind" { width:auto; max-width:80% }


Note that not all possible justifications are tracked, if
merge($n_1, n_2, j$) is invoked but already $\rootNode(n_1) = \rootNode(n_2)$, then
the justification $j$ for the equality of $n_1, n_2$ is dropped.
In contrast __egg__ [@EggProofs] keeps track of potential extra paths to find _short_ proofs.
Use cases within CDCL(T), that leverages amortized effect of backtracking search typically
hedge on that the cost finding a strongest conflict up front is outweighed by multiple attempts that converge on
sufficiently strong conflicts.

#### From justifications to proofs

We can create proofs from first-principles by using justifications.
Suppose $\rootNode(s) = \rootNode(t)$ follows from a sequence
merge($s_1, t_1, \ell_1$), merge($s_2, t_2, \ell_2$),$\ldots$, merge($s_k, t_k, \ell_k$).


Then a proof of $s \simeq t$ can be extracted using overloaded functions $\pi$:


~ Math
\begin{array}{ll}
   \proof(s \simeq t) & =
   \begin{array}{c}
   \AxiomC{$\proof(s \stackrel{j}{\rightarrow} \cdots a)$}
   \AxiomC{$\proof(t \stackrel{j'}{\rightarrow} \cdots a)$}
   \RightLabel{symm}
   \UnaryInfC{$a \simeq t$}
   \RightLabel{trans}
   \BinaryInfC{$s \simeq t$}
   \DisplayProof\\[2em]
   \mbox{$a$ is a least common $\rightarrow$ ancestor of $s, t$}
   \end{array}
\end{array}
~

~Math
\begin{array}{ll}
   \proof(s \stackrel{j}{\rightarrow} t \stackrel{j'}{\rightarrow} \cdots u) & =
   \begin{array}{c}
   \AxiomC{$\proof(j, s \simeq t)$}
   \AxiomC{$\proof(t \stackrel{j'}{\rightarrow} \cdots u)$}
   \RightLabel{trans}
   \BinaryInfC{$s \simeq u$}
   \DisplayProof
   \end{array}
   \\[1.5em]
   \proof(s) & =
   \begin{array}{c}
   \AxiomC{\mbox{}}
   \RightLabel{refl}
   \UnaryInfC{$s \simeq s$}
   \DisplayProof
   \end{array}
   \\[1.5em]
   \proof(\ell : s \simeq t, s \simeq t) & = \ell
   \\[1.5em]
   \proof(\ell : t \simeq s, s \simeq t) & = 
   \begin{array}{c}
   \AxiomC{$\ell$}
   \RightLabel{symm}
   \UnaryInfC{$s \simeq t$}
   \DisplayProof    
   \end{array}
   \\[1.5em]
   \proof(cc: f(ts) \simeq f(ts'), f..) & =
   \begin{array}{c}
   \AxiomC{$\proof(ts_1 \simeq ts'_1), \ldots, \proof(ts_k \simeq ts'_k)$}   
   \RightLabel{cong}
   \UnaryInfC{$f(ts) \simeq f(ts')$}
   \DisplayProof
   \end{array}
\end{array}
~



#### Control

* Congruence closure and Boolean reasoning
  * Do enough CC to speed up search (unit propagation)
  * Don't do too much CC when Boolean search takes care of it.

#### A note on complexity



[INCLUDE="arithmetic.mdk"]

## Reducible Theories

### Refinement Types
Let us illustrate a use of _reduction_ from richer theories to base theories based on 
a simple example based on refinement types. 
It encodes refinement types using auxiliary functions as explained
in [@JacobsCategorical]. Refinement types are not part of Z3 so the decision procedure we outline
here is not available out of the box. One way to realize this theory is externally through the UserPropagator
facility.

Abstractly, a refinement
type of sort $S$ uses a predicate $p$ over $S$. At least one element of $S$ must satisfy $p$ for the
construction to make sense. The refinement type $S \mid p$ represents the elements of $S$ that satisfy
$p$. The properties we need to know about elements of $S\mid p$ can be encoded using two auxiliary
functions that form a surjection $\restrictOp$ from $S \mid p$ into $S$ with a partial inverse $\restrictOp$ that maps
elements from $S$ into $S \mid p$. The properties of these functions are summarized as follows:

~MathPre
  p : S \rightarrow Bool
  \relaxOp : S \mid p \rightarrow S
  \restrictOp : S \rightarrow S \mid p
  \forall x : S \mid p \ . \ \restrictOp(\relaxOp(x)) = x
  \forall s : S \ . \ p(s)\ \rightarrow \ \relaxOp(\restrictOp(s)) = s
  \forall x : S \mid p \ . \ p(\relaxOp(x))
~

Let us illustrate the sort of natural numbers as a refinement type of integers:

~Example

~~MathPre
  sort Nat = Int \mid \lambda x \ . \ x \geq 0
  \forall n : Nat \ . \ \restrictOp(\relaxOp(n)) = n \wedge \relaxOp(n) \geq 0
  \forall i : Int \ . \ i \geq 0 \rightarrow \relaxOp(\restrictOp(i)) = i
~~

~

We obtain a theory solver for formulas with refinement types by instantiating these axioms whenever there is a term $t$ introduced
of sort $S \mid p$ introduced as part of the input or during search (from instantiating quantifiers).
The main challenge with supporting this theory is to ensure that the new terms introduced from axiom instantiation 
is bounded. We don't want the solver to create terms $\relaxOp(\restrictOp(\relaxOp(\restrictOp(\ldots))))$.


* For every sub-term of the form $\restrictOp(t)$, where $t$ is not $\relaxOp(t')$ instantiate the axiom:
  * $p(t) \Rightarrow \relaxOp(\restrictOp(t)) = t$

* For every term $t$ of sort $S \mid p$ instantiate the axioms:
    * $\restrictOp(\relaxOp(t)) = t$
    * $p(\relaxOp(t))$ 


### Arrays

The theory of arrays in SMTLIB is formally based on two functions `select` and `store` and an axiomatization

~MathPre
  \mathit{select}(\Astore(A, i, v), j) = \mathbf{if}\ i \simeq j\ \mathbf{then}\ v\ \mathbf{else}\ \mathit{select}(A, j) \\
  \forall i . \mathit{select}(A, i) \simeq \mathit{select}(B, i) \implies A \simeq B
~
for every array $A, B$, index $i, j$ and value $v$. Alluding to the intent that the theory of arrays
is useful for modeling arrays in programming languages will henceforth use $A[i]$ when we mean $\mathit{select}(A, i)$.


Z3 reduces the theory of arrays to reasoning about uninterpreted functions.
It furthermore treats arrays as function spaces which assuming more axioms about arrays.
he first-order theory of arrays axiomatized above enjoys compactness and so the following formula is satisfiable[^jazzman]

[^jazzman]: thanks to Jasmin Blanchette for drawing attention to this distinction.

~Math
\forall a : Array(Int, Int) \ . \ \exists k \ . \ \forall i \geq k \ . \ a[i] \simeq 0.
~

The same formula is not satisfiable when arrays range over function spaces.
The distinction is only relevant when checking satisfiability of quantified formulas over arrays.
In addition to functions $\Astore$ and $\mathit{select}$ z3 includes built-in
functions $\Amap$, $\Aconst$ and the operator $\Aasarray$ and lambdas.
It includes also the function $\Aext$ that provides a witness term for distinct arrays,
and $\delta(A)$ for accessing a _default_ value.


The central functionality of the decision procedure for arrays is to ensure
that a satisfying model under the theory of EUF translates to a satisfying
model in the theory of arrays. To this end, the main service of the theory
solver is to saturate the search state with $\beta$ reduction axioms
for array terms that admit beta-reduction. We call these terms $\lambda$ terms
and they are defined by the beta-reduction axioms:
~MathPre
\beta(\Astore(A,j,v)[i]) & = & \mathit{if}\ i \simeq j\ \mathit{then} \ v \ \mathit{else}\ A[i]
\beta(\Amap(f,A,B)[i]) & = & f(A[i],B[i])
\beta(\Aasarray(f)[i]) & = & f(i)
\beta(\Aconst(v)[i]) & = & v
\beta((\lambda x \ . \ M)[i]) & = & M[i/x]
~

The reduction into EUF, is then in a nutshell an application of the following inference rule:

~Math
\AxiomC{$b$ is a lambda term}
\AxiomC{$a[j]$ is a term}
\AxiomC{$b \sim a$ ($a, b$ are equal under EUF)}
\TrinaryInfC{$b[j] = \beta(b[j])$}
\DisplayProof
~

together with an infernce rule to enforce extensionality

~Math
A[\Aext(A,B)] \simeq B[\Aext(A, B)] \implies A \simeq B
~

The decision procedure enforces several throttles [@ArrayFMCAD09] to avoid instantiating axioms when they are redundant.
We here describe the main data-structures used by the instantiation engine. 

The decision procedure maintains for every array node $n$ the following sets

~ MathPre
\mathit{ParentSelects}(n) & = & \{ A[i] \mid A \sim n \} 
\mathit{ParentLambdas}(n) & = & \{ \Astore(A,i,v) \mid A \sim n\} \cup \{ \Amap(f, \ldots, A, \ldots) \mid A \sim n \} 
\mathit{Lambdas}(n)       & = & \{ \Aconst(v) \mid \Aconst(v) \sim n \} \cup 
                          &   & \{ \Amap(f,\ldots) \mid \Amap(f,\ldots) \sim n \} \cup 
                          &   & \{ \Astore(\ldots) \mid \Astore(\ldots) \sim n \} \cup 
                          &   & \{ \Aasarray(f) \mid \Aasarray(f) \sim n \} \cup 
                          &   & \{ \lambda x \ . \ M \mid \lambda x \ . \ M \sim n \} 
~

When $n_1$ is merged with $n_2$, and $n_1$ is the new root, the sets from $n_2$ are added to $n_1$.
The merge also looks for new redexes when $n$ and $n'$ are merged:

* Assert $\lambda[j] = \beta(\lambda[j])$ for every $A[j] \in \mathit{ParentSelects}(n)$, $\lambda \in \mathit{ParentLambdas}(n')$
* Assert $\lambda[j] = \beta(\lambda[j])$ for every $A[j] \in \mathit{ParentSelects}(n)$, $\lambda \in \mathit{Lambdas}(n')$

For enforcing $\Astore(A, i, v)[j] = \beta(\Astore(A, i, v)[j])$ the solver only instantiates the axiom $i \simeq j \lor \Astore(A, i, v)[j] \simeq A[j]$
because the axiom $\Astore(A,i,v)[i] \simeq v$ is instantiated eagerly when the term $\Astore(A, i, v)$ is created.

Extensionality is enforced on pairs of array terms $A, B$, that are in _shared_ positions. An array term is in a shared position when it occurs on side of an equality or under a function that is not part of the theory of arrays. Furthermore, to ensure that semantics of lambdas, if $A \equiv \lambda x \ . \ M$ is a lambda term in a shared position
and $B$ is in a shared position, the axiom $A \simeq B \implies \forall i \ . \ M[x/i] \simeq B[i]$ is instantiated. Thus, lambda equality is at this point
enforced by straight-forward instantiation.



### Algebraic Datatypes

The theory of algebraic datatypes is an SMTLIB2 standard [@SMTLIB2]. The theory
allows to declare a `datatype` sort, or set of mutually recursive `datatypes` sorts.
The elements of an algebraic datatypes is the least set generated by the constructors in the type declaration.
You can declare algebraic data-types in SMTLIB2 using the `declare-datatypes` command

```
(declare-datatypes ((Tree 1) (TreeList 1))
     (
      (par (T)  (Tree leaf (node (value T) (children (TreeList T)))))
      (par (T) (TreeList nil (cons (car (Tree T)) (cdr (TreeList T)))))
     )
)
```

A legacy format that is less flexible, but a bit easier to formulate, is also available.

```
(declare-datatypes (T) ((Tree leaf (node (value T) (children TreeList)))
                        (TreeList nil (cons (car Tree) (cdr TreeList)))))
```


Z3 supports datatypes nested with sequences and arrays. 
The example below uses `Stmt' nested in a sequence.

```
(declare-sort Expr)
(declare-sort Var)
(declare-datatypes ((Stmt 0)) 
  (((Assignment (lval Var) (rval Expr)) 
    (If (cond Expr) (th Stmt) (el Stmt)) 
    (Seq (stmts (Seq Stmt))))))
```

For arrays, the datatype are allowed only in the range of arrays.

~ Framed
Provide example with nested arrays
~

We will in the following use the notation $C$ for a constructor, for example `Assignment` is a constructor;
$acc_1, \ldots, acc_n$ for accessors corresponding to $C$, for example `lval` and `rval` are accessors
corresponding to the constructor `Assignment`. The predicate symbol $isC(t)$ is true if the term $t$
is equal to term headed by the constructor $C$. The construct $\{ t \mbox{ with } \mathit{field} := s \}$
assigns term $s$ to an accessor _field_ for the term $t$. Note that it is possible to apply an
accessor to a data-type constructor that does not match. For example taking the head of an empty list,
$\mathit{head}(\mathit{nil})$. The interpretation of $\mathit{head}(\mathit{nil})$ is not fixed by the
theory, instead $\mathit{head}$ is treated as an uninterpreted function.

The theory solver for algebraic datatypes is implemented by adding theory axioms on demand. 
The theory axioms rely on the theory of uninterpreted functions.
It builds a finite interpretation for every node of sort data-type and adds theory axioms
on demand.
Every E-node $n$ of data-type sort is assigned a constructor representation, initially _null_. 
If $n$ is equated to a node $n'$ whose function is labeled by a constructor $C$, 
the representative for $n$ is labeled
by $n'$. 

#### Saturation Rules

The saturation rules add theory axioms on demand to enforce that the
theory of algebraic datatypes axioms are satisfied in a consistent state.
Accessor axioms, update-field axioms are added as soon as terms are created.
Recognizer axioms are added when the truth value of a recognizer is asserted.
If a datatype has a single constructor the recognizer is asserted as a unit.
Occurs check is applied lazily. It ensures that the partially constructed
model corresponds to acyclic algebraic datatypes.

#### Accessor axioms:
If $n$ is a constructor node $C(a_1, \ldots, a_m)$ assert the axioms

~ MathPre
  n \simeq C(a_1, \ldots, a_m) \implies acc_1(n) \simeq a_1 \land \ldots \land acc_m(n) \simeq a_m
~

#### Update field axioms:
If $n$ is of the form $n := \{ r \ \mathbf{with}\ field := v \}$, where $\mathit{field}$ is an accessor for constructor $C$, 
then assert the axioms

~ MathPre
  isC(r)      & \implies  &  acc_j(n) \simeq acc_j(r) & \mbox{for} & acc_j \neq \mathit{field} 
  isC(r)      & \implies  &  \mathit{field}(n) \simeq v 
  \neg isC(r) & \implies  &  n \simeq r
  isC(r)      & \implies  &  isC(n)
~

##### Recognizers
For recognizer atom we have to ensure that a node is assigned to a constructor that is consistent
with the assignment to the recognizer atom. Thus, if $isC(n)$ is asserted to true, then $n$ must be 
equated to a term with constructor $C$. Conversely, if $n$ is assigned with a constructor $C' \neq C$, 
then $isC(n)$ is false. The decision procedure ensures this correspondence lazily. If $isC(n)$ is asserted
to true, then it ensures the axiom
~ MathPre
  isC(n) \implies n \simeq C(acc_1(n), \ldots, acc_m(n))  
~
where $acc_1, \ldots, acc_m$ are the accessors for $C$.

If $isC(n)$ is asserted to false, but $n$ equal to a node $n'$ that is headed by $C$, then it creates the conflict clause:

~ MathPre
   n \simeq n' \implies isC(n) & \mbox{if} & n' \mbox{ is of the form $C(\ldots)$}
~

~ Framed
Something about covering constructors so all possible constructors are tested.
~

##### Occurs check

An occurs check violation is detected when there is a state satisfying the properties
$n_1 \simeq n_1', n_2 \simeq n_2', \ldots, n_k \simeq n_1$
where each $n_i'$ is of the form $C_i(\ldots, n_{i+1}, \ldots)$.
Occurs checks are performed lazily in a _final_ check.

#### Model construction rules

Dually to saturation rules, the theory solver builds a finite model for algebraic datatypes.
Model construction is interlaved with the CDCL(T) engine in a way that has subtle consequences.
Model construction drives the constraints to a goal state where all terms ranging over an algebraic datatype have been assigned a constructor 
and all saturation rules have been applied. If there is a term that has not been assigned a constructor, the solver attempts to first guess
an assignment to the term based on a non-recursive base case for the data-type (for mutually recursive data-types some types don't have 
xnon-recursive base cases, it is possible to drive towards a nested sub-term that has).
The fact that the solver can guess a fixed base case constructor during model construction relies on the assumptions for theory combinations:
other theories need only distinguish whether data-type terms are equal or distinct. The shape of terms is opaque to other theories.
If a term $t$ cannot be assigned a non-recursive base case (say _nil_), it is assigned a non-recursive constructor (say, _cons_), that eventually
allows assigning $t$ to a term that is arbirarily deep and therefore can be distinct from any set of other terms $t_2, t_3, \ldots$.

The approach for model construction does not work if we introduce a sub-term predicate $t \preceq s$.
The theory of algebraic data-types can be extended to the subterm relation while remaining decidable.
If $t, s$ range over an algebraic data-type with two base case constructors $\mathit{nil}_1$ and $\mathit{nil}_2$, 
and $s = \mathit{nil}_2$. Then _unfairly_ guessing only $\mathit{nil}_1$ before guessing _cons_, but neglegting $\mathit{nil}_2$
leads to non-termination of a model constructing decision procedure with the sub-term relation. 



#### Quantifier Elimination and Algebraic Datatypes

The theory of algebraic data-types admits partial quantifier elimination.

~ Framed
Present MBP for ADT here specifically?
~



<!--- ### Special Relations --->

## Hybrid Theories
A prime example of a hybrid theory in Z3 is the theory of strings, 
regular expressions and sequences.

The theory of strings and regular expressions has entered mainstream SMT solving
thanks to community efforts around standardization and solvers. The SMTLIB2 format
for unicode strings [@SMTLIB2]. It integrates operations that mix equational solving
over the free monoid with integer arithmetic (for string lengths and extracting sub-strings).
Regular expression constraints furthermore effectively introduce constraints that require
unfolding recursive relations. Z3 uses symbolic derivatives [@stanford2020symbolic] to 
handle regular expressions, noteworthy, with complementation and intersection handled 
by derivatives.

A second prolific example of a hybrid theory is Z3's model-based quantifier instantiation engine (MBQI).
Here, a theory is encoded using a quantifier. The MBQI engine supports extensions of
Bradley-Manna-Sipma's array property fragment [@BradleyMS06] that effectively combines arithmetic with
uninterpreted functions.


### Sequences/Strings/Regex

### Floating points
Floating point semantics can mainly be defined in terms of bit-vector operations. The solver for floating points
uses this connection to reduce the theory of floating points to bit-vectors.
There are also operations on floating points that connect with the theory of Reals. For formulas combining
floating points and reals, the theory solver bridges bit-vector values with bounds over the Reals.
