# Decision Procedures


We will apply the following taxonomy when discussing the theory solvers.
It extends the reduction approach to decision procedures [@KapurZarbaReduction]
as explained in the context of Z3 in [@MouraB09].


* Base theories - other theory solvers build on top of base theories
  * The base theories in Z3 are Boolean theories, the theory of uninterpreted functions and the theory of arithmetic.
* Reducible theories 
  * Theories that can be solved by reducing directly into base theories.
  * Instances: Arrays, IEEE floating points, algebraic data-types, recursive functions.
* Hybrid theories 
  * Theories that combine non-disjoint signatures from different theories.
  * Instances: Sequences, Model-based quantifier instantiation.
* External theories 
  * Theories that may be developed externally by propagating consequences and identifying conflicts.
  * Instance: an external propagator plugin.


~ Figure { #fig-z3core; caption: "Architecture of Z3's SMT Core solver." }
~~ Snippet

\begin{picture}(270,210)(0,-10)

\multiput(75,40)(0,77){3}{\oval(20,20)[tr]}
\multiput(75,0)(0,77){3}{\oval(20,20)[br]}
\multiput(10,40)(0,77){3}{\oval(20,20)[tl]}
\multiput(0,0)(0,77){3}{\line(0,1){40}}
\multiput(85,0)(0,77){3}{\line(0,1){40}}
\multiput(10,50)(0,77){3}{\line(1,0){65}}
\multiput(10,-10)(0,77){3}{\line(1,0){65}}
\multiput(10,0)(0,77){3}{\oval(20,20)[bl]}

\put(16,155){\shortstack{E-matching\\ based \\ Quantifier\\ Instantiation}}
\put(16, 92){\shortstack{EUF + SAT}}
\put(16,0){\shortstack{Model\\ based \\ Quantifier\\ Instantiation}}

\put(267,195){\oval(20,20)[tr]}
\put(267,0){\oval(20,20)[br]}
\put(149,195){\oval(20,20)[tl]}
\put(149,0){\oval(20,20)[bl]}
\put(149,-10){\line(1,0){120}}
\put(149,205){\line(1,0){120}}
\put(139,0){\line(0,1){195}}
\put(277,0){\line(0,1){195}}


\multiput(255,20)(0,37){5}{\oval(20,20)[tr]}
\multiput(255,10)(0,37){5}{\oval(20,20)[br]}
\multiput(165,10)(0,37){5}{\oval(20,20)[bl]}
\multiput(165,20)(0,37){5}{\oval(20,20)[tl]}
\multiput(155,10)(0,37){5}{\line(0,1){10}}
\multiput(265,10)(0,37){5}{\line(0,1){10}}
\multiput(165,30)(0,37){5}{\line(1,0){90}}
\multiput(165,0)(0,37){5}{\line(1,0){90}}
\put(170,12){Strings/Sequences}
\put(185,50){Datatypes}
\put(185,86){Bit-vectors}
\put(195,122){Arrays}
\put(185,158){Arithmetic}
\put(190,190){Theories}

\put(42,50){\vector(0,1){17}}
\put(42,67){\vector(0,-1){17}}
\put(42,127){\vector(0,1){17}}
\put(42,144){\vector(0,-1){17}}

\put(85,95){\vector(1,0){54}}
\put(139,95){\vector(-1,0){54}}

\end{picture}
~~
~




## Boolean Theories
Bit-vectors are in the current solver treated as tuples of Boolean variables and all bit-vector
operations are translated to Boolean SAT. The approach is called bit-blasting.
Only mild equational reasoning is performed over bit-vectors.
The benefits of the CDCL SAT engine have been mostly enjoyed for applications in symbolic execution 
of 32-bit arithmetic instructions. Bit-blasting has its limitations: applications that use quantifiers
and applications around smart contracts that use 256 bits per word are stressing this approach. A
revised bit-vector solver that integrates algebraic reasoning and lazy bit-blasting is therefore currently
being developed.

Cardinality and Pseudo-Boolean inequalities can also be translated into CNF clauses. It is often an advantage
when there are very few variables in the summations, but the overhead of translation can quickly become
impractical. Z3 therefore contains dedicated solvers for cardinality and Pseudo-Boolean constraints.

~ Begin Example

Bit-blasting the arithmetic expression $x + y \ge 2$ assuming both $x$ and $y$ consist of $2$ bits results in the formula 

~~ MathPre
z_1 &\equiv (x_1 \vee y_1) \wedge (\lnot x_1 \vee \lnot y_1)
c_2 &\equiv (x_1 \wedge y_1)
z_2 &\equiv (x_2 \vee y_2 \vee c_2) \wedge (\lnot x_2 \vee y_2 \vee c_2) \wedge (x_2 \vee \lnot y_2 \vee \lnot c_2) \wedge (\lnot x_2 \vee \lnot y_2 \vee \lnot c_2)
z_2&
~~

the result of the summation is given by $z = (z_1, z_2)$. $c_2$ is the carry of adding the first bits of $x$ and $y$.
Pseudo-Boolean constraints like $x + \lnot y + 2z \ge 2$ can be translated in multiple ways like translating it to bit-vector addition/multiplication as before, translating it to decision-diagrams or sorting-networks.

A decision diagram for this constraint looks like
~~ MathPre
if z:&&&
& true&&
else:&&&
& if x:&&
&&if \lnot y:&
&&& true
&&else:&
&&&false
&else:
&&false&
~~
which can be translated to a propositional formula. The sorting network approach sorts the bit-sequence $\langle x, \lnot y, z, z\rangle$ to a sequence $\langle s_1, s_2, s_3, s_4 \rangle$ and asserts that $s_3$ has to be true.

The native solver instead tracks the partial sum of already assigned booleans and sets some of the remaining ones in case it is not possible to exceed the desired bound without them.

~ End Example

[INCLUDE="euf.mdk"]


[INCLUDE="arithmetic.mdk"]

## Reducible Theories


### Refinement Types
Let us illustrate a use of _reduction_ from richer theories to base theories based on 
a simple example based on refinement types. 
It encodes refinement types using auxiliary functions, as explained
in [@JacobsCategorical]. Refinement types are not part of Z3, so the decision procedure we outline
here is not available out of the box. One way to realize this theory is externally through the User-Propagator
facility.

Abstractly, a refinement
type of sort $S$ uses a predicate $p$ over $S$. At least one element of $S$ must satisfy $p$ for the
construction to make sense. The refinement type $S \mid p$ represents the elements of $S$ that satisfy
$p$. The properties we need to know about elements of $S\mid p$ can be encoded using two auxiliary
functions that form a surjection $\relaxOp$ from $S \mid p$ into $S$ with a partial inverse $\restrictOp$ that maps
elements from $S$ into $S \mid p$. The properties of these functions are summarized as follows:

~MathPre
  p : S \rightarrow Bool
  \relaxOp : S \mid p \rightarrow S
  \restrictOp : S \rightarrow S \mid p
  \forall x : S \mid p \ . \ \restrictOp(\relaxOp(x)) = x
  \forall s : S \ . \ p(s)\ \rightarrow \ \relaxOp(\restrictOp(s)) = s
  \forall x : S \mid p \ . \ p(\relaxOp(x))
~

Let us illustrate the sort of natural numbers as a refinement type of integers:

~Example

~~MathPre
  sort Nat = Int \mid \lambda x \ . \ x \geq 0
  \forall n : Nat \ . \ \restrictOp(\relaxOp(n)) = n \wedge \relaxOp(n) \geq 0
  \forall i : Int \ . \ i \geq 0 \rightarrow \relaxOp(\restrictOp(i)) = i
~~

~

We obtain a theory solver for formulas with refinement types by instantiating these axioms whenever there is a term $t$ introduced
of sort $S \mid p$ introduced as part of the input or during search (from instantiating quantifiers).
The main challenge with supporting this theory is to ensure that the new terms introduced from axiom instantiation 
are bounded. We don't want the solver to create terms $\relaxOp(\restrictOp(\relaxOp(\restrictOp(\ldots))))$.


* For every sub-term of the form $\restrictOp(t)$, where $t$ is not $\relaxOp(t')$ instantiate the axiom:
  * $p(t) \Rightarrow \relaxOp(\restrictOp(t)) = t$

* For every term $t$ of sort $S \mid p$ instantiate the axioms:
    * $\restrictOp(\relaxOp(t)) = t$
    * $p(\relaxOp(t))$ 


### Arrays

The theory of arrays in SMTLIB is formally based on two functions `select` and `store` and an axiomatization

~MathPre
  \mathit{select}(\Astore(A, i, v), j) = \mathbf{if}\ i \simeq j\ \mathbf{then}\ v\ \mathbf{else}\ \mathit{select}(A, j) \\
  \forall i . \mathit{select}(A, i) \simeq \mathit{select}(B, i) \implies A \simeq B
~
for every array $A, B$, index $i, j$ and value $v$. Alluding to the intent that the theory of arrays
is useful for modeling arrays in programming languages will henceforth use $A[i]$ when we mean $\mathit{select}(A, i)$.


Z3 reduces the theory of arrays to reasoning about uninterpreted functions.
It furthermore treats arrays as function spaces, which assuming more axioms about arrays.
The first-order theory of arrays axiomatized above enjoys compactness and so the following formula is satisfiable[^jazzman]

[^jazzman]: thanks to Jasmin Blanchette for drawing attention to this distinction.

~Math
\forall a : Array(Int, Int) \ . \ \exists k \ . \ \forall i \geq k \ . \ a[i] \simeq 0.
~

The same formula is not satisfiable when arrays range over function spaces.
The distinction is only relevant when checking satisfiability of quantified formulas over arrays.
In addition to functions $\Astore$ and $\mathit{select}$ Z3 includes built-in
functions $\Amap$, $\Aconst$ and the operator $\Aasarray$ and lambdas.
It includes also the function $\Aext$ that provides a witness term for distinct arrays,
and $\delta(A)$ for accessing a _default_ value.


The central functionality of the decision procedure for arrays is to ensure
that a satisfying model under the theory of EUF translates to a satisfying
model in the theory of arrays. To this end, the main service of the theory
solver is to saturate the search state with $\beta$ reduction axioms
for array terms that admit beta-reduction. We call these terms $\lambda$ terms
and they are defined by the beta-reduction axioms:
~MathPre
\beta(\Astore(A,j,v)[i]) & = & \mathit{if}\ i \simeq j\ \mathit{then} \ v \ \mathit{else}\ A[i]
\beta(\Amap(f,A,B)[i]) & = & f(A[i],B[i])
\beta(\Aasarray(f)[i]) & = & f(i)
\beta(\Aconst(v)[i]) & = & v
\beta((\lambda x \ . \ M)[i]) & = & M[i/x]
~

The reduction into EUF, is then, in a nutshell, an application of the following inference rule:

~Math
\AxiomC{$b$ is a lambda term}
\AxiomC{$a[j]$ is a term}
\AxiomC{$b \sim a$ ($a, b$ are equal under EUF)}
\TrinaryInfC{$b[j] = \beta(b[j])$}
\DisplayProof
~

together with an inference rule to enforce extensionality

~Math
A[\Aext(A,B)] \simeq B[\Aext(A, B)] \implies A \simeq B
~

The decision procedure enforces several throttles [@MouraB09] to avoid instantiating axioms when they are redundant.
We here describe the main data-structures used by the instantiation engine. 

The decision procedure maintains for every array node $n$ the following sets

~ MathPre
\mathit{ParentSelects}(n) & = & \{ A[i] \mid A \sim n \} 
\mathit{ParentLambdas}(n) & = & \{ \Astore(A,i,v) \mid A \sim n\} \cup \{ \Amap(f, \ldots, A, \ldots) \mid A \sim n \} 
\mathit{Lambdas}(n)       & = & \{ \Aconst(v) \mid \Aconst(v) \sim n \} \cup 
                          &   & \{ \Amap(f,\ldots) \mid \Amap(f,\ldots) \sim n \} \cup 
                          &   & \{ \Astore(\ldots) \mid \Astore(\ldots) \sim n \} \cup 
                          &   & \{ \Aasarray(f) \mid \Aasarray(f) \sim n \} \cup 
                          &   & \{ \lambda x \ . \ M \mid \lambda x \ . \ M \sim n \} 
~

When $n_1$ is merged with $n_2$, and $n_1$ is the new root, the sets from $n_2$ are added to $n_1$.
The merge also looks for new redexes when $n$ and $n'$ are merged:

~ Math
\AxiomC{$n \sim n'$}
\AxiomC{$A[j] \in \mathit{ParentSelects}(n)$}
\AxiomC{$\lambda \in \mathit{Lambdas}(n') \cup \mathit{ParentLambdas}(n')$}
\TrinaryInfC{$n \simeq n' \implies \lambda[j] = \beta(\lambda[j])$}
\DisplayProof
~

For enforcing $\Astore(A, i, v)[j] = \beta(\Astore(A, i, v)[j])$, the solver only instantiates the axiom $i \simeq j \lor \Astore(A, i, v)[j] \simeq A[j]$
because the axiom $\Astore(A,i,v)[i] \simeq v$ is instantiated eagerly when the term $\Astore(A, i, v)$ is created.

Extensionality is enforced on pairs of array terms $A, B$, that are in _shared_ positions. An array term is in a shared position when it occurs on one side of an equality or under a function that is not part of the theory of arrays. Furthermore, to ensure congruence for lambdas, if $A \equiv \lambda x \ . \ M$ is a lambda term in a shared position
and $B$ is in a shared position, the axiom $\lambda x \ . \ M \simeq B \implies \forall i \ . \ M[x/i] \simeq B[i]$ is instantiated. Thus, lambda equality is 
at the time of writing
enforced by a reduction to quantified formulas.



### Algebraic Datatypes

The theory of algebraic data-types is an SMTLIB2 standard [@SMTLIB2]. The theory
allows declaring a `datatype` sort, or a set of mutually recursive `datatypes` sorts.
The elements of an algebraic datatype are the least set generated by the constructors in the type declaration.
You can declare algebraic data-types in SMTLIB2 using the `declare-datatypes` command

```
(declare-datatypes ((Tree 1) (TreeList 1))
     (
      (par (T)  (Tree leaf (node (value T) (children (TreeList T)))))
      (par (T) (TreeList nil (cons (car (Tree T)) (cdr (TreeList T)))))
     )
)
```

A legacy format that is less flexible, but a bit easier to formulate, is also available.

```
(declare-datatypes (T) ((Tree leaf (node (value T) (children TreeList)))
                        (TreeList nil (cons (car Tree) (cdr TreeList)))))
```


Z3 supports datatypes nested with sequences and arrays. 
The example below uses `Stmt' nested in a sequence.

```
(declare-sort Expr)
(declare-sort Var)
(declare-datatypes ((Stmt 0)) 
  (((Assignment (lval Var) (rval Expr)) 
    (If (cond Expr) (th Stmt) (el Stmt)) 
    (Seq (stmts (Seq Stmt))))))
```

For arrays, datatypes are allowed only in the range of arrays.

~ Framed
Provide example with nested arrays
~

We will in the following use the notation $C$ for a constructor, for example `Assignment` is a constructor;
$acc_1, \ldots, acc_n$ for accessors corresponding to $C$, for example `lval` and `rval` are accessors
corresponding to the constructor `Assignment`. The predicate symbol $isC(t)$ is true if the term $t$
is equal to a term headed by the constructor $C$. The construct $\{ t \mbox{ with } \mathit{field} := s \}$
assigns the term $s$ to an accessor _field_ for the term $t$. Note that it is possible to apply an
accessor to a data-type constructor that does not match. For example, taking the head of an empty list,
$\mathit{head}(\mathit{nil})$. The interpretation of $\mathit{head}(\mathit{nil})$ is not fixed by the
theory, instead $\mathit{head}$ is treated as an uninterpreted function.

The theory solver for algebraic datatypes is implemented by adding theory axioms on demand. 
The theory axioms rely on the theory of uninterpreted functions.
It builds a finite interpretation for every node of sort data-type and adds theory axioms
on demand.
Every E-node $n$ of data-type sort is assigned a constructor representation, initially _null_. 
If $n$ is equated to a node $n'$ whose function is labeled by a constructor $C$, 
the representative for $n$ is labeled
by $n'$. 

#### Saturation Rules

The saturation rules add theory axioms on demand to enforce that the
theory of algebraic datatypes axioms are satisfied in a consistent state.
Accessor axioms, update-field axioms are added as soon as terms are created.
Recognizer axioms are added when the truth value of a recognizer is asserted.
If a datatype has a single constructor, the recognizer is asserted as a unit.
The occurs check is applied lazily. It ensures that the partially constructed
model corresponds to acyclic algebraic datatypes.

#### Accessor axioms:
If $n$ is a constructor node $C(a_1, \ldots, a_m)$ assert the axioms

~ MathPre
  n \simeq C(a_1, \ldots, a_m) \implies acc_1(n) \simeq a_1 \land \ldots \land acc_m(n) \simeq a_m
~

#### Update field axioms:
If $n$ is of the form $n := \{ r \ \mathbf{with}\ field := v \}$, where $\mathit{field}$ is an accessor for constructor $C$, 
then assert the axioms

~ MathPre
  isC(r)      & \implies  &  acc_j(n) \simeq acc_j(r) & \mbox{for} & acc_j \neq \mathit{field} 
  isC(r)      & \implies  &  \mathit{field}(n) \simeq v 
  \neg isC(r) & \implies  &  n \simeq r
  isC(r)      & \implies  &  isC(n)
~

##### Recognizers
For recognizer atom we have to ensure that a node is assigned to a constructor that is consistent
with the assignment to the recognizer atom. Thus, if $isC(n)$ is asserted to true, then $n$ must be 
equated to a term with constructor $C$. Conversely, if $n$ is assigned with a constructor $C' \neq C$, 
then $isC(n)$ is false. The decision procedure ensures this correspondence lazily. If $isC(n)$ is asserted
to true, then it ensures the axiom
~ MathPre
  isC(n) \implies n \simeq C(acc_1(n), \ldots, acc_m(n))  
~
where $acc_1, \ldots, acc_m$ are the accessors for $C$.

If $isC(n)$ is asserted to false, but $n$ equal to a node $n'$ that is headed by $C$, then it creates the conflict clause:

~ MathPre
   n \simeq n' \implies isC(n) & \mbox{if} & n' \mbox{ is of the form $C(\ldots)$}
~

~ Framed
Something about covering constructors so all possible constructors are tested.
~

##### Occurs check

An occurs check violation is detected when there is a state satisfying the properties
$n_1 \simeq n_1', n_2 \simeq n_2', \ldots, n_k \simeq n_1$
where each $n_i'$ is of the form $C_i(\ldots, n_{i+1}, \ldots)$.
Occurs checks are performed lazily in a _final_ check.

#### Model construction rules

Dually to saturation rules, the theory solver builds a finite model for algebraic datatypes.
Model construction is interleaved with the CDCL(T) engine in a way that has subtle consequences.
Model construction drives the constraints to a goal state where all terms ranging over an algebraic datatype have been assigned a constructor 
and all saturation rules have been applied. If there is a term that has not been assigned a constructor, the solver attempts to first guess
an assignment to the term based on a non-recursive base case for the data-type (for mutually recursive data-types some types don't have 
non-recursive base cases, it is possible to drive towards a nested sub-term that has).
The fact that the solver can guess a fixed base case constructor during model construction relies on the assumptions for theory combinations:
other theories need only distinguish whether data-type terms are equal or distinct. The shape of terms is opaque to other theories.
If a term $t$ cannot be assigned a non-recursive base case (say _nil_), it is assigned a non-recursive constructor (say, _cons_), that eventually
allows assigning $t$ to a term that is arbitrarily deep and therefore can be distinct from any set of other terms $t_2, t_3, \ldots$.

The approach for model construction does not work if we introduce a sub-term predicate $t \preceq s$.
The theory of algebraic data-types can be extended to the subterm relation while remaining decidable.
If $t, s$ range over an algebraic data-type with two base case constructors $\mathit{nil}_1$ and $\mathit{nil}_2$, 
and $s = \mathit{nil}_2$. Then _unfairly_ guessing only $\mathit{nil}_1$ before guessing _cons_, but neglecting $\mathit{nil}_2$
leads to non-termination of a model constructing decision procedure with the sub-term relation. 



#### Quantifier Elimination and Algebraic Datatypes

The theory of algebraic data-types admits partial quantifier elimination.

~ Framed
Present MBP for ADT here specifically?
~



<!--- ### Special Relations --->

## Hybrid Theories
A prime example of a hybrid theory in Z3 is the theory of strings, 
regular expressions and sequences.

The theory of strings and regular expressions has entered mainstream SMT solving
thanks to community efforts around standardization and solvers. The SMTLIB2 format
for unicode strings [@SMTLIB2]. It integrates operations that mix equational solving
over the free monoid with integer arithmetic (for string lengths and extracting sub-strings).
Regular expression constraints furthermore effectively introduce constraints that require
unfolding recursive relations. Z3 uses symbolic derivatives [@stanford2020symbolic] to 
handle regular expressions, noteworthy, with complementation and intersection handled 
by derivatives.

A second prolific example of a hybrid theory is Z3's model-based quantifier instantiation engine (MBQI).
Here, a theory is encoded using a quantifier. The MBQI engine supports extensions of
Bradley-Manna-Sipma's array property fragment [@BradleyMS06] that effectively combines arithmetic with
uninterpreted functions.


### Sequences/Strings/Regex

### Floating points
Floating point semantics can mainly be defined in terms of bit-vector operations. The solver for floating points
uses this connection to reduce the theory of floating points to bit-vectors.
There are also operations on floating points that connect with the theory of Reals. For formulas combining
floating points and reals, the theory solver bridges bit-vector values with bounds over the Reals.
