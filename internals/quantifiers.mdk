# Quantifiers

The dedicated engines QSAT [#sec-qsat] and SPACER [#sec-spacer] handle classes of quantified formulas.
The QSAT engine solves formulas using quantifier alternation over theories that allow quantifier elimination using model-based projection.
The SPACER engine solves constrained Horn clauses over a limited set of theories (with arithmetic being central and including emerging
support for algebraic datatypes, arrays and bit-vectors).

Quantifier reasoning is also available within the CDCL(T) core. Here it relies on _quantifier instantiation_ engines.
We describe the main engines in use.

The quantifier instantiation engines rely on auxiliary annotations with quantifiers.
We elided them when first introducing terms in Section [#sec-terms-and-formulas].
The fields that are of relevance to quantifier instantiation are expanded below:

```koka
type Expr
   Var{ index : int; sort : Sort }
   App{ f : FuncDecl; args : list<Expr> }
   Quantifier{ b : Binder; decl : list<Declaration>; body : Expr; 
               patterns : list<list<Expr>>; 
               nopatterns : list<Expr>;
               weight : int;
               qid : symbol }

```

* A set of _multi_ patterns are used by the E-matching engine to search for instantiations. Quantifiers can be manually annotated by patterns or if no patterns are annotated, z3 infers a set of patterns based on smallest subterms. More than one pattern might be needed to find a full instantiation of all quantified variables. 

* A set of _non-patterns_ that identify sub-terms that cannot be used as patterns. It provides a user with control over quantifier instantiation by the E-matching engine.

* A _weight_ to provide priortization of quantifier instantiation.

* A _quantifier identifier_ (_qid_) which can be used to trace instantiations of a quantifier in logs.

## E-matching [@MouraB07]

Let us start with an example of quantifier instantiation using E-matching in action.

~ Begin Example

Consider the formula 

~~ Math
  \underbrace{(\forall x \ . \ f(g(x,c)) \simeq a)}_{p_\varphi} \land b \simeq c \land g(c,b) \simeq c \land f(b) \not\simeq a
~~

The smallest subterm properly containing the bound variable $x$ is ${\color{red}g(x,c)}$ in $f({\color{red}g(x,c)}) \simeq a$.
The only other occurrence of the function $g$ is $g(c,b)$ in the equality $g(c,b) \simeq c$.
Based on the ground equality $b \simeq c$ it follows $g(c,c) \sim g(c,b)$ so we can instantiate $x$ by $c$ and infer

~~ Math
  p_{\varphi} \rightarrow f(g(b,c)) \simeq a
~~ 
The formulas are now ground unsatisfiable.

~ End Example


Quantifier instantiation using E-matching in Z3 serves a sweet spot by producing instantiations that take 
congruences of equalities into account, quickly, across a large set of terms and incrementally.

### E-matching - basic algorithm

E-matching is a first-order matching algorithm that takes a congruence closure into account when checking for equality.
We can describe a basic E-matching algorithm as taking

* a _pattern_ that may contain variables, 
* an E-node _n_, with set of equal nodes accessed as _n.siblings_,

and producing substitutions that represent the set of matches for _n_ with respect to _pattern_.


```python    
def match(pattern, \($n$\), \($\theta$\)):
    pattern = pattern\($\theta$\)
    if pattern == \($n$\):
       yield \($\theta$\)
    elif is_var(pattern):
       yield \($\theta[$\)pattern\($\mapsto$\) \($n$\)\($]$\)
    else:
       f(patterns) = pattern
       for f(terms) in \($n.\mathit{siblings}$\):  
          # e.g., with same head function symbol f
          for \($\theta'$\) in matches(patterns, terms, \($\theta$\)):
            yield \($\theta'$\)

def matches(patterns, terms, \($\theta$\)):
    if not patterns:
       yield \($\theta$\)
       return
    for \($\theta'$\) in match(patterns[0], terms[0], \($\theta$\)):
        for \($\theta''$\) in matches(patterns[1:], terms[1:], \($\theta'$\)):
            yield \($\theta''$\)
```

The same algorithm can be presented in equational form with an extra argument $S$
that accumulates substitutions.

~MathPre

 match(x, t, S)     &  =    & \{ \theta[x \mapsto t] \;\mid\; \theta \in S, x \not\in \theta \} 
                    &       & \cup  \{ \theta \;\mid\; \theta \in S, x \in \theta, \theta(x) \in t.\mathit{siblings} \}
 match(c, t, S)     &  =    & \emptyset\                 \mathsf{if} c \not\in t.\mathit{siblings}
 match(c, t, S)     &  =    & S                 \mathsf{if} c \in t.\mathit{siblings}
 match(f(ps), t, S) &  =    & \bigcup_{f(ts) \in cc(t)} match(ps_n, ts_n, \ldots, 
                    &       &                                 match(ps_1, ts_n, S))
~

### E-matching - code trees 

The straight-forward E-matching algorithm is expensive when it is invoked from scratch for every possible 
candidate of pattern and node during search. To share work across patterns and terms, Z3 compiles patterns
into a _code tree_ data-structure that contains a dynamically compiled set of instructions to perform matching.
The instructions can be regarded as a partial evaluation of the naive algorithm for fixed patterns. The
instruction set allows merging code sequences from different patterns by sharing common prefixes.
Substitutions are stored in registers, backtracking just updates the registers.

The abstract matching machine uses an array of registers $reg[i]$ to store sub-terms. 
Instructions are stored at program counters and each instruction refers to a next program counter.

Consider the following pattern

~ Math
              f(X, g(X,a), h(Y), b)
~ 

It compiles into a sequence of instructions as follows:

|----------|-------------------------|---------------------------------------------------|
| PC       | Instruction             |                                                   |
+----------+-------------------------+---------------------------------------------------+
| $pc_0$   | init(f, $pc_1$)         |    add arguments of $f$ to registers 1-4          |
+----------+-------------------------+---------------------------------------------------|
| $pc_1$   | check(4,$b$,$pc_2$)     |    check if $reg[4]$ is congruent to $b$          | 
+----------+-------------------------+---------------------------------------------------+
| $pc_2$   | bind(2, $g$, 5, $pc_3$) |    bind terms in $reg[2]$ with $g$ to $5-6$       |
+----------+-------------------------+---------------------------------------------------+
| $pc_3$   | compare(1, 5, $pc_4$  ) |    check if $reg[1]$ equals $reg[5]$              |
+----------+-------------------------+---------------------------------------------------+
| $pc_4$   | check(6, $a$, $pc_5$)   |    check if $reg[6]$ is congruent to $a$          |
+----------+-------------------------+---------------------------------------------------+
| $pc_5$   | bind(3, $h$, 7, $pc_6$) |    bind terms in $reg[3]$ with $h$ to $7$         |
+----------+-------------------------+---------------------------------------------------+
| $pc_6$   | yield(1,7)              |    output binding from $reg[1], reg[7]$           |
+----------+-------------------------+---------------------------------------------------+

Let us trace the instructions for the term $f(h(a),g(h({\color{red}{c}}), a), h(c),b)$

|----------|-------------------------|---|------------------------------------------------|
| PC       | Instruction             |   | $f(h(a),g(h({\color{red}{c}}), a), h(c),b)$                      |
+----------+-------------------------+---+------------------------------------------------+
| $pc_0$   | init(f, $pc_1$)         |   | $reg[1:4] \leftarrow h(a), g(h({\color{red}{c}}),a), h(c), b$ |
+----------+-------------------------+---+------------------------------------------------|
| $pc_1$   | check(4,$b$,$pc_2$)     |   | $reg[4] = b$                                   | 
+----------+-------------------------+---+------------------------------------------------+
| $pc_2$   | bind(2, $g$, 5, $pc_3$) |   | $reg[5:6] \leftarrow h({\color{red}{c}}), a$                  |
+----------+-------------------------+---+------------------------------------------------+
| $pc_3$   | compare(1, 5, $pc_4$  ) |   | $reg[1] = h(a) \neq h({\color{red}{c}}) = reg[5]$             |
+----------+-------------------------+---+------------------------------------------------+
| $pc_4$   | check(6, $a$, $pc_5$)   |                                                   ||
+----------+-------------------------+---------------------------------------------------||
| $pc_5$   | bind(3, $h$, 7, $pc_6$) |                                                   ||
+----------+-------------------------+---------------------------------------------------||
| $pc_6$   | yield(1,7)              |                                                   ||
+----------+-------------------------+---------------------------------------------------||


If we instead use the term $f(h(a),g(h({\color{blue}{a}}), a), h(c),b)$, we get the following execution

|----------|-------------------------|---|------------------------------------------------|
| PC       | Instruction             |   | $f(h(a),g(h({\color{blue}{a}}), a), h(c),b)$      |
+----------+-------------------------+---+------------------------------------------------+
| $pc_0$   | init(f, $pc_1$)         |   | $reg[1:4] \leftarrow h(a), g(h({\color{blue}{a}}),a), h(c), b$ |
+----------+-------------------------+---+------------------------------------------------|
| $pc_1$   | check(4,$b$,$pc_2$)     |   | $reg[4] = b$                                   | 
+----------+-------------------------+---+------------------------------------------------+
| $pc_2$   | bind(2, $g$, 5, $pc_3$) |   | $reg[5:6] \leftarrow h({\color{blue}{a}}), a$                  |
+----------+-------------------------+---+------------------------------------------------+
| $pc_3$   | compare(1, 5, $pc_4$  ) |   | $reg[1] = h(a) = h({\color{blue}{a}}) = reg[5]   $             |
+----------+-------------------------+---+------------------------------------------------+
| $pc_4$   | check(6, $a$, $pc_5$)   |   | $reg[6] = a$                                   |
+----------+-------------------------+---+------------------------------------------------|
| $pc_5$   | bind(3, $h$, 7, $pc_6$) |   | $reg[7] \leftarrow c$                          |
+----------+-------------------------+---+------------------------------------------------|
| $pc_6$   | yield(1,7)              |   | $X \leftarrow h(a) = reg[1], Y \leftarrow c = reg[7]$ |
+----------+-------------------------+---+------------------------------------------------|


Patterns that share common (top-down) term structure can share code sequences.

  *  This saves on common work.

  *  Use the choice instruction to branch when patterns end up having different sub-terms.

Other instructions are possible, 

   *  forward pruning: lookahead multiple function symbols in immediate subterms before diving into any subterm.

   *  to deal with _multi-patterns_, when matching more than one pattern at a time.

### Inverted path indexing

During search, congruence classes are merged and we would like to learn which merges
should trigger new pattern match attempts. Z3 uses a filter called an _inverted path index_
that tracks when a pattern is potentially useful for matching. 

~ Example
The pattern $f(X, g(X,a), h(Y), b)$ contains the subterm $g(X, a)$ in position 2.
The merge between $n_1$ and $n_2$ can potentially trigger a new match when
$n_1.\mathit{siblings}$ contains a node labeled by $g$, and $n_2$ has a parent labeled by $f$, 
and occurs as a second position of $f$.
~

Z3 pre-computes an index based on $f, g$ pairs like these and check if it is triggered 
for some $f, g$ pair and pattern when nodes $n_1, n_2$ are merged.

### Relevance Propagation

Z3 uses _relevance propagation_ to harness quantifier instantiation.
Relevance propagation attempts to emulate semantic tableau rules on top of the CDCL(T) engine.
In a semantic tableau, a formula is decomposed based on top-level connectives. Depending on the connectives, it creates
one or more branches. Different branches then contain only atomic subformulas that are relevant to establishing that
the formula in the root is true. We list tableau rules for a minimal set of logical connectives as inference rules:

~~ Math
\begin{array}{ccc}
    \AxiomC{$\bigvee_{i=1}^k \phi_i$}
    \RightLabel{$\vee$}
    \UnaryInfC{$\phi_1 \mid \ldots \mid \phi_k$}
    \DisplayProof
& & 
    \AxiomC{$\neg \bigvee_{i=1}^k \phi_i$}
    \RightLabel{$\neg \vee$}
    \UnaryInfC{$\neg \phi_1, \ldots, \neg \phi_k$}
    \DisplayProof    
\\
&
\AxiomC{$\neg\neg\varphi$}
\RightLabel{$\neg\neg$}
\UnaryInfC{$\varphi$}
\DisplayProof
&
\\
\AxiomC{$\varphi\leftrightarrow \psi$}
\RightLabel{$\leftrightarrow$}
\UnaryInfC{$\varphi,\psi \mid \neg\varphi, \neg\psi$}
\DisplayProof
& &
\AxiomC{$\neg(\varphi\leftrightarrow \psi)$}
\RightLabel{$\leftrightarrow$}
\UnaryInfC{$\varphi,\neg\psi \mid \neg\varphi, \psi$}
\DisplayProof
\\
\AxiomC{$\mathit{ite}(\varphi,\psi,\theta)$}
\RightLabel{$\mathit{ite}$}
\UnaryInfC{$\varphi,\psi \mid \neg\varphi,\theta$}
\DisplayProof
& &
\AxiomC{$\mathit{ite}(\varphi,\psi,\theta)$}
\RightLabel{$\neg\mathit{ite}$}
\UnaryInfC{$\varphi,\theta \mid \neg\varphi,\psi$}
\DisplayProof
\end{array}
~~

The rules are read top-down: To establish satisfiability of the formula at the root tableau rules create branches, separated by $\mid$. A branch is closed
if it contains a pair of complementary sub-formulas (one is the negation of the other). Otherwise a branch is open.

Relevancy propagation follows the flow of the inference rules:

* Let $\phi$ be shorthand for $\bigvee_{i} \phi_i$. If $\phi$ is assigned true and is marked as relevant, then the first child $\phi_i$ that gets assigned true is marked relevant. If $\phi$ is assigned false and is marked as relevant, then all children are marked relevant.
* Let $\psi$ be shorthand for $(\phi_1 \leftrightarrow \phi_2)$. If $\psi$ is marked as relevant, then both $\phi_1$ and $\phi_2$ are marked as relevant.
* Let $\theta$ be $ite(\theta_1, \theta_2, \theta_3)$. If $\theta$ is marked as relevant, then if $\theta_1$ is assigned to true (false), then $\theta_2$ ($\theta_3$) is marked as relevant.

### The life-cycle of E-matching.

When formulas are parsed and asserted, they are converted into clauses. Quantified formulas are treated as atomic formulas. They are opaque relative to the CDCL(T) engine
and treated as if they are propositional atoms. It is only when quantified formulas are asserted, either at base level during search or during backtracking, that
E-matching kicks in.

The E-matching engine reacts to the following updates to the state during search:

* A universally quantified formula $\forall x, \pi(x) \ . \ \varphi$ with pattern $\pi$ is assigned to true. In this case, the pattern $\pi(x)$ is compiled into a
sequence of matching instructions and the instructions are inserted into the current code-tree. Upon backtracking, when the formula $\forall x, \pi(x) \ . \ \varphi$
is no longer assigned to true, the instructions from the pattern $\pi$ are removed.
* When a term $f(t)$ becomes relevant, the matching engine triggers a lookup on the function $f$ to determine if $f(t)$ can potentially trigger a new match.
* When two equivalence classes (of relevant terms) are merged by congruence closure, the E-matching engine examines whether the equivalence class merge can trigger a match.

Note that all state updates are reversed during backtracking. Only lemmas that were created as a side-effect of conflicts
survive backtracking and become the seeds for what quantifiers, terms and equivalences that survive.

When E-matching triggers a quantifier instantiation it creates a formula $((\forall x \ . \ \varphi[x]) \implies \varphi[t])$, which is universally valid.
The formula is asserted as an axiom. The formula is never garbage collected as long as search stays within the backtracking scope of where the instance was created.
It gets garbage collected during backtracking if the instantiation happens within a nested search level. 


### Prioritizing Quantifier Instantiation

The _weight_ field on quantifiers is used to assign a priority to quantifier instantiation.
Quantifiers with _weight_ set to 0 are instantiated without delay. Quantifiers with higher weights
are inserted into a quantifier instantiation queue. The queue is emptied based on a set of rules:

* The _cost_ of a quantifier is computed as a function of the _weight_ other attributes using an expression 
that can be configured by setting the parameter `smt.qi.cost`. The default value of `smt.qi.cost` is 
`(+ weight generation)`, where _weight_ is obtained from the quantifier and _generation_ keeps track of instantiation depths. 
All terms have initially generation 0, terms created as a by-product of quantifier instantiation have 1 plus the maximal
generation of previous terms. Other parameters that can be used to encode quantifier priorities include
  * `instances` number of instances of current branch
  * `size` number of sub-expression of the quantifier
  * `depth` depth of quantified expression
  * `vars` number of bound variables
  * `pattern_width` number of patterns in multi-pattern annotation
  * `total_instances` the number of existing instances based on the quantifier
  * `scope` the scope level of search (how many case splits)
  * `cs_factor` a case split factor computed by considering number of disjuncts in a quantified body

* Quantifiers are instantiated eagerly if their cost is below a configurable `smt.qi.eager_threshold`.
* A partial checker can be enabled by setting `smt.qi.quick_checker` to 1 or 2 to promote instantiation where quantified instantiations are known to close a branch.
* Quantifiers whose cost are above the eager threshold and does not pass a quick checker are inserted into a _lazy_ queue.

The _lazy_ queue is instantiated on _final_ checks. It uses a cost threshold to iteratively increase the number of instances that are processed.

* All quantifiers with cost below `smt.qi.lazy_threshold` are instantiated during final check.


## Model-based Quantifier Instantiation [@GeM09;@MouraB10;@BonacinaLM11;@WintersteigerHM13]

Model-based Quantifier Instantiation, MBQI, is based on a simple concept of using ground models
to model check quantifiers, and extracting substitutions from quantifiers that fail the model check.
Conceptually, MBQI uses the procedure:

Check $\psi \land \forall x \ . \ \varphi[{x}]$\

__while__ $\psi$ is SAT with model $M$:\
\ \  __if__  $\neg \varphi^M[{x}]$ is UNSAT __return__ SAT\
\ \  $M \leftarrow $ model for $\neg \varphi^M[{x}]$ \
\ \  find $t$, such that $x \not\in t, t^M = x^M$.\
\ \  $\psi \leftarrow \psi \land \varphi[t]$\
__return__ UNSAT\

where $t^M$ is $t$ partially evaluated using interpretation $M$.

~ Begin Example

Assume we have a model $M := [y \mapsto 3, f(x) \mapsto \mathit{if}\ x = 1\ \mathit{then}\ 3\ \mathit{else} \ 5]$
and term $t :=  y + f(y) + f(z)$.
Then the specialization of $t$ with respect to $M$ is
~~ Math
t^M = 8 + \mathit{if}\ z = 1\ \mathit{then}\ 3\ \mathit{else} \ 5
~~
~ End Example

MBQI offers a powerful setting to perform quantifier reasoning when
the search space for instantiation terms is finite. This is the case for several fragments:
EPR, UFBV, Array property fragment, Essentially UF.
MBQI can also be combined with a set of templates to search over instantiation terms.


### EPR

Effectively Propositional Reasoning, also known as Bernays-Schoenfinkel-Ramsey class comprises
for formulas with relations, equalities, universally quantified variables, constants but no functions.
Formally, it can be described as a set of formulas of the form:

~MathPre
EPR & ::= \exists e_1\ldots e_n \forall u_1\ldots u_m F
F   & ::= \bigwedge_i C_i
C   & ::= \bigvee_j L_i
L   & ::= A | \neg A
A   & ::= p(\vec{V}) | V = V'
V   & ::= e_i | u_j
~

EPR is decidable, as seen from a brute-force decision procedure:

* Skolemize 
  * $\forall u_1\ldots u_m F$, the $e_1, \ldots, e_n$ are free constants
* Instantiate 
  * $\bigwedge_{\theta} F\theta$ 
  * where $\theta$ ranges over all bindings of $u_i$ to $e_j$.
* Check ground SAT
* Ground SAT implies finite model of size at most $n$.

MBQI can be used to harness the set of groundings.

* Skolemize
  * $\forall u_1\ldots u_m F$, the $e_1, \ldots, e_n$ are free constants

* Models for $\neg F$ bind variables $u_1, \ldots, u_m$ to free constants

* The number of possible such models is bounded by $m^n$.


### UFBV [@WintersteigerHM13]

~ MathPre
F   & ::= \exists e_i : bv[n] . F | \forall u_j : bv[n] . F | F \wedge F | C
C   & ::= \bigvee_j L_i
L   & ::= A | \neg A
A   & ::= p(\vec{T}) | T = T' | \mathtt{bvle}(T, T') | \ldots
T   & ::= f(\vec{T}) | e_i | u_j | \mbox{bit-vector expression}
bv[n] & ::= \mbox{bit-vector of length $n$}
~


UFBV is decidable:

* All variables range over finite domains.

* Quantifier-free fragment is not only NP hard, it is NEXPTIME hard.
  * QF-UFBV can be encoded into EPR. [@SeidlLB12]

* Quantified fragment is another complexity jump.

* BV - quantifier elimination [@JohnC16;@JohnC13;@JohnC11]

* UFBV using MBQI [@WintersteigerHM13]
  * Use templates to find general instances

### Map Property Fragment [@BradleyMS06]

~ MathPre
MP    & ::= \exists \vec{e} . \forall \vec{u} . \bigwedge (G \Rightarrow F)
G     & ::= G \wedge G | A_G
A_G   & ::= T[u] \simeq T[u] | T[] \not\simeq T[u]
T[x]  & ::= x | e
F     & ::= F \vee F | A_F | \neg A_F
A_F   & ::= T[a[u]] \simeq T[a[u]] 
~

where $a$ are arrays and $T[]$ denotes just $e$.

~ Begin Example

Let us express the following in the Map Property Fragment:

* $a$ is the constant $e$-array.

* $a$ is equal to $b$ except at index $v$.

* $c$ can only have two values, $e_1$ or $e_2$.

~~ MathPre
  \forall u \ . \ a[u] \simeq e
  \forall u \ . \ u \not\simeq v \ \Rightarrow a[u] \simeq b[u]
  \forall u \ . \ c[u] \simeq e_1 \ \vee c[u] \simeq e_2
~~

~ End Example
 
### Array Property Fragment [@BradleyMS06]

The Array Property Fragment extends the Map Property Fragment by allowing limited arithmetic.

~ MathPre
AP   & ::= \exists \vec{e} . \forall \vec{u} . \bigwedge (G \Rightarrow F)
G    & ::= G \wedge G | A_G
A_G  & ::= T_G \geq T_G
T_G  & ::= u | T[]
T[x]  & ::= x | e | k\times T[x] | T[x] + T[x]
F    & ::= F \vee F | A_F | \neg A_F
A_F  & ::= T_F \geq T_F | R(T_F, \ldots, T_F) 
T_F  & ::= T[a[u]]
k    & ::= \mbox{a numeric constant}
R    & ::= \mbox{a predicate}
~

The claim is that the array property fragment admits a finite set of instantiations.

* Given formula $\varphi := \forall \vec{u} . \bigwedge (G \Rightarrow F)$ with $\vec{e}$ free.

* Let $\mathcal{I} = \{ c_1, \ldots, c_m \}$ be set of a set of $T[] \cup \{ 0 \}$ from $\varphi$.

~ Definition
The set $\mathcal{I}$ is a _sufficient set of instances_ for $\varphi$, if
  
    $\forall u \ . \ \bigvee_{c \in \mathcal{I}} \bigwedge_{A_G} (A_G \Rightarrow A_G[c/u])$
 
~

* In other words, for every possible instantiation of $u$ there is a $c$
  that satisfies at least the same combination of guards.


~ Proposition
  If $\varphi$ admits a finite sufficient set of instances $\mathcal{I}$, it can be evaluated using those.
~

~ Proposition
  Formulas in the array and map property fragments admit a sufficient set of instantiations.
~

~ Proposition
  MBQI is a decision procedure for the array and map property fragments by using the
  instantiation sets computed from the formulas.
~

Instantiations based on $\mathcal{I}$ are sufficient for establishing unsatisfiability.
To establish satisfiability, MBQI updates models that are based on how uninterpreted functions
evaluate on arguments in $\mathcal{I}$ to how they evaluate on all integers.
Models are updated in ways that do not change the interpretation of quantifier-free formulas.
This is accomplished by keeping interpretation of ground terms the same, but adjusting the interpretations
of functions for values that are not in the ground interpretation.
For arithmetic and bit-vectors it updates functions to be piecewise constant between values from $\mathcal{I}$.
In other words, suppose $\mathcal{I} = \{ c_1, c_2, \ldots, c_k \}$, and the set happens to be sorted such that
$\mathcal{M}(c_1) \leq \mathcal{M}(c_2) \leq \ldots \leq \mathcal{M}(c_k)$, and suppose $f$ is a function from integers to integers.
The ground model $\mathcal{M}$ interprets $f(c_1), \ldots, f(c_k)$ and has some dummy interpretation for $f$ for values outside of
$\{ \mathcal{M}(c_1), \mathcal{M}(c_2), \ldots, \mathcal{M}(c_k) \}$. Model fixing changes the dummy interpretation of $f$
to a piecewise constant interpretation by using the values from this set. For $x < \mathcal{M}(c_1)$ it sets the interpretation of
$f(x) = \mathcal{M}(f(c_1))$. For $x$ between $\mathcal{M}(c_i)$ and $\mathcal{M}(c_{i+1})$ it has the option to set the
the interpretation of $f(x)$ to either $\mathcal{M}(f(c_i))$ or $\mathcal{M}(f(c_{i+1}))$.

Z3 represents the updated interpretations to the function $f$ using _projection functions_.
In other words, it uses the original interpretation of $f$ as an interpretation to a fresh function $f_{aux}$,
and then interprets $f(x)$ as $f_{aux}(f_\pi(x))$, where $f_\pi$ is a projection function. The projection
function maps an integer $x$ to the bound $c_i$ or $c_{i+1}$, where $\mathcal{M}(c_i) \leq x \leq \mathcal{M}(c_{i+1})$.

Models are also updated by detecting macro patterns in quantified formulas.
For example, a quantified formula $\forall x \ . \ f(x) = t$, where $f$ is not used in $t$ defines $f$ as a macro.
The interpretation of $f(x)$ is a function of $t$. Z3 uses several techniques to extract macro interpretations from
quantified formulas. After exhausting the search for macro interpretations it fixes the models for remaining functions
to be piecewise constant.

### Essentially Uninterpreted Fragment [@GeM09]

The Array Property Fragment can be seen as an instance of a class of formulas,
where instantiations can be extracted based on a set of grammar rules that are extracted
from the formulas.

This fragment thus applies to a wider range of formulas than the syntactic array property fragment.
It also captures fragments studied in different contexts:

* the list property fragment by McPeak and Necula
* several locally finite theories by Stokkermans et. al.


~ Begin Example

```smt
(set-option :smt.mbqi true)
;; f an g are "streams"
(declare-fun f (Int) Int)
(declare-fun g (Int) Int)

;; the segment [a, n + a] of stream f is equal to the segment [0, n] of stream g.
(declare-const n Int)
(declare-const a Int)
(assert (forall ((x Int)) (=> (and (<= 0 x) (<= x n))
                              (= (f (+ x a)) (g x)))))

;; adding some constraints to a
(assert (> a 10))
(assert (>= (f a) 2))
(assert (<= (g 3) (- 10)))

(check-sat)
(get-model)
```

~ End Example

## Quantifier Elimination through Macro Introduction

An important ingredient in quantifier reasoning is found in pre-processing.
Pre-processing techniques may identify quantified assertions as macro definitions.
Z3 contains several heuristics for identifying macros.

### Tactic macro-finder

The tactic finds implicit macro definitions in quantifiers. 
A main instance of a macro an equality that defines a function `f` using some term `t` that does not contain `f`.
Other instances of macros are also recognized by the macro finder.

* `(forall (x) (= (f x) t))`

* `not (= (p x) t)` is recognized as `(p x) = (not t)`

* `(iff (= (f x) t) cond)`  rewrites to `(f x) = (if cond t else (k x))`
   * add clause `(not (= (k x) t))`

* `(= (+ (f x) s) t)` becomes `(= (f x) (- t s))`

* `(= (+ (* -1 (f x)) x) t)`  becomes `(= (f x) (- (- t s)))`

### Tactic elim-predicates

The elim-predicates subsumes `macro-finder` (and the `quasi-macro` tactic that we skip describing).
In addition to the `macro-finder` macros it identifies rewrite opportunities of the form

* `(assert (forall ((x Int) (y Int)) (= (f x y (+ x y)) (* 2 x y))))` that implies that `f` can be treated
as a function `(f x y z) = (if (= z (+ x y)) (* 2 x y) (f' x y z))`

* Predicates that occur at most in every clause and such that the cross-product of positive 
and negative occurrences is small relative to the original set of occurrences are eliminated. 
The elimination process was introduced by Davis and Putnam in a seminal paper that preceeded the 
Davis Logeman Loveland backtracking SAT procedure. We illustrate the functionality of `elim-predicates` 
with an example


```smt
(declare-fun f (Int Int Int) Int)
(declare-fun p (Int) Bool)
(declare-const a Int)
(declare-const b Int)

(assert (forall ((x Int) (y Int)) (= (f x y (+ x y)) (* 2 x y))))
(assert (p (f 8 a (+ a 8))))
(assert (not (p (f 0 a (+ a 8)))))
(assert (not (p (f 2 a (+ a 8)))))
(assert (not (p (f 1 a (+ a b)))))
(apply elim-predicates)
```

The result of the tactic is a goal of the form:

```smt
(goal
  (not (= (* 16 a) (f!0 0 a (+ 8 a))))
  (not (= (* 16 a) (f!0 2 a (+ 8 a))))
  (let ((a!1 (= (* 16 a) (ite (= 1 b) (* 2 a) (f!0 1 a (+ a b))))))
    (not a!1))
  :precision precise :depth 1)
```

<!---
## Deprecated
* [@PiskacMB10] EPR using relational algebra, [@MouraB08a] Superposition, see also [VampireZ3]

[VampireZ3]: https://vprover.github.io "VampireZ3"
--->